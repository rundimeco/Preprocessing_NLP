{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a50d8e-3cbb-451a-82b5-1490e45c370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I travelling Nancy NLP ' Université Lorraine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceres/anaconda3/lib/python3.10/site-packages/stopwordsiso/_core.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# --- Preprocessing (kept simple) ---\n",
    "import re\n",
    "\n",
    "#!pip install stopwordsiso\n",
    "import stopwordsiso\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "def don(text): \n",
    "    return text\n",
    "    \n",
    "def lower(text): \n",
    "    return text.lower()\n",
    "\n",
    "URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "def remove_urls(text): \n",
    "    return URL_RE.sub(\"\", text)\n",
    "    \n",
    "def replace_urls(text): \n",
    "    return URL_RE.sub(\" <URL> \", text)\n",
    "    \n",
    "PUNCT_RE = re.compile(r\"[^\\w\\s]\")\n",
    "def remove_punct(text): \n",
    "    return PUNCT_RE.sub(\" \", text)\n",
    "\n",
    "TOKEN_PUNC = re.compile(r\"\\w+|[^\\w\\s]\")\n",
    "\n",
    "def remove_stopwords(text, lg=\"all\"):\n",
    "    #very slow but keeps punctuation\n",
    "    stoplist = stopwordsiso.stopwords(['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et',\n",
    "                                       'fi', 'fr', 'hu', 'it', 'lt', 'lv', 'mt', 'nl',\n",
    "                                       'pl', 'pt', 'ro', 'sk', 'sl', 'sv'])\n",
    "    return \" \".join([T for T in TOKEN_PUNC.findall(text) if T not in set(stoplist)])\n",
    "\n",
    "def compose(*funcs):\n",
    "    def f(text):\n",
    "        for fn in funcs:\n",
    "            text = fn(text)\n",
    "        return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return f\n",
    "\n",
    "PREPROCESSORS = {\n",
    "    \"DON\": don,\n",
    "    \"LOW\": lower,\n",
    "    #\"URLrem\": remove_urls,\n",
    "    #\"URLrep\": replace_urls,\n",
    "    \"PUN\": remove_punct,\n",
    "    \"RSW\": remove_stopwords,\n",
    "    #\"LOW+URLrem\": compose(lower, remove_urls),\n",
    "    #\"LOW+URLrep\": compose(lower, replace_urls),\n",
    "    #\"LOW+PUN\": compose(lower, remove_punct),\n",
    "    \"LOW+URLrem+PUN\": compose(lower, remove_urls, remove_punct),\n",
    "    #\"LOW+URLrep+PUN\": compose(lower, remove_urls, remove_punct),\n",
    "    \"LOW+URLrem+PUN+RSW\": compose(lower, remove_urls, remove_punct, remove_stopwords),\n",
    "    #\"LOW+URLrep+PUN+RSW\": compose(lower, replace_urls, remove_punct, remove_stopwords),\n",
    "\n",
    "}\n",
    "multi_string = \"I am travelling to Nancy for an NLP course à l'Université de Lorraine\"\n",
    "print(multi_string)\n",
    "print(remove_stopwords(multi_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7377c5d-f8ae-4222-ad74-3bd1b9bad943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 42\n",
    "OUTFILE = Path(\"results_DiagLang.csv\")\n",
    "\n",
    "macro_f1 = make_scorer(f1_score, average=\"macro\")\n",
    "SCORING = {\"acc\": \"accuracy\", \"macro_f1\": macro_f1}\n",
    "\n",
    "def mean_scores(scores):\n",
    "    return {k.replace(\"test_\", \"\"): float(np.mean(v))\n",
    "            for k, v in scores.items() if k.startswith(\"test_\")}\n",
    "    \n",
    "MODEL = LogisticRegression(max_iter=2000, random_state=SEED)\n",
    "\n",
    "def evaluate(X, y, preprocess, vectorizer):\n",
    "    Xp = [preprocess(t) for t in X]\n",
    "    pipe = Pipeline([\n",
    "        (\"vect\", vectorizer),\n",
    "        (\"clf\", MODEL),\n",
    "    ])\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    scores = cross_validate(pipe, Xp, y, cv=cv, scoring=SCORING, n_jobs=-1)\n",
    "    return mean_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b500aa92-133c-4790-9368-f32a801408ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 5984 Labels: ['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'it', 'lt', 'lv', 'mt', 'nl', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv']\n"
     ]
    }
   ],
   "source": [
    "#! unzip corpus_multi.zip\n",
    "import json\n",
    "with open(\"corpus_multi.json\") as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "X, y = [x[0] for x in json_data], [x[1] for x in json_data]\n",
    "print(\"Samples:\", len(X), \"Labels:\", sorted(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912b965e-3f9d-458d-9811-b087f8373dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep: DON          | Vec: count_word_1-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vec_name, vec \u001b[38;5;129;01min\u001b[39;00m VECTORIZERS\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprep_name\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m12s\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Vec: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvec_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[1;32m     20\u001b[0m     rows\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m: prep_name,\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: vec_name,\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mres\n\u001b[1;32m     24\u001b[0m     })\n",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(X, y, preprocess, vectorizer)\u001b[0m\n\u001b[1;32m     24\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     25\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvect\u001b[39m\u001b[38;5;124m\"\u001b[39m, vectorizer),\n\u001b[1;32m     26\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m\"\u001b[39m, MODEL),\n\u001b[1;32m     27\u001b[0m ])\n\u001b[1;32m     28\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mSEED)\n\u001b[0;32m---> 29\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSCORING\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_scores(scores)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:399\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 399\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "VECTORIZERS = {\n",
    "    \"count_word_1-1\": CountVectorizer(analyzer=\"word\", ngram_range=(1, 1), lowercase=False, max_features= 1000),\n",
    "    #\"count_word_1-2\": CountVectorizer(analyzer=\"word\", ngram_range=(1, 2), lowercase=False, max_features= 1000),\n",
    "    \"tfidf_word_1-1\": TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 1), lowercase=False, max_features= 1000),\n",
    "    #\"tfidf_word_1-2\": TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), lowercase=False, max_features= 1000),\n",
    "    \"count_char_3-5\": CountVectorizer(analyzer=\"char\", ngram_range=(3, 5), lowercase=False, max_features= 1000),\n",
    "    #\"count_charwb_3-5\": CountVectorizer(analyzer=\"char_wb\", ngram_range=(3, 5), lowercase=False, max_features= 1000),\n",
    "    \"tfidf_char_3-5\": TfidfVectorizer(analyzer=\"char\", ngram_range=(3, 5), lowercase=False, max_features= 1000),\n",
    "    #\"tfidf_charwb_3-5\": TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3, 5), lowercase=False, max_features= 1000),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for prep_name, prep in PREPROCESSORS.items():\n",
    "    for vec_name, vec in VECTORIZERS.items():\n",
    "        print(f\"Prep: {prep_name:12s} | Vec: {vec_name}\")\n",
    "        res = evaluate(X, y, prep, vec)\n",
    "        print(res)\n",
    "        rows.append({\n",
    "            \"preprocessing\": prep_name,\n",
    "            \"vectorizer\": vec_name,\n",
    "            **res\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee99085b-b92d-4270-9704-5ba28f5d084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   preprocessing      vectorizer       acc  macro_f1\n",
      "16           RSW  count_word_1-1  0.996658  0.996659\n",
      "8            URL  count_word_1-1  0.995488  0.995507\n",
      "0            DON  count_word_1-1  0.995321  0.995342\n",
      "12           PUN  count_word_1-1  0.995321  0.995342\n",
      "14           PUN  count_char_3-5  0.995154  0.995170\n",
      "4            LOW  count_word_1-1  0.994987  0.995022\n",
      "10           URL  count_char_3-5  0.994820  0.994829\n",
      "6            LOW  count_char_3-5  0.994486  0.994507\n",
      "2            DON  count_char_3-5  0.994485  0.994487\n",
      "17           RSW  tfidf_word_1-1  0.994151  0.994262\n",
      "1            DON  tfidf_word_1-1  0.988636  0.989112\n",
      "13           PUN  tfidf_word_1-1  0.988636  0.989112\n",
      "9            URL  tfidf_word_1-1  0.988469  0.988944\n",
      "5            LOW  tfidf_word_1-1  0.986797  0.987434\n",
      "15           PUN  tfidf_char_3-5  0.985294  0.986151\n",
      "7            LOW  tfidf_char_3-5  0.984959  0.985867\n",
      "11           URL  tfidf_char_3-5  0.984960  0.985861\n",
      "3            DON  tfidf_char_3-5  0.984792  0.985716\n",
      "Saved to: results_DiagLang.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(rows).sort_values(\"macro_f1\", ascending=False)\n",
    "print(df)#if \"RSW\" improves results, is it because of English ?\n",
    "\n",
    "df.to_csv(OUTFILE, index=False)\n",
    "print(f\"Saved to: {OUTFILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f33d6e-a70a-43a2-a1d7-de8a0e2bae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceres/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.4.0).\n",
      "Path to dataset files: /home/ceres/.cache/kagglehub/datasets/azimulh/tweets-data-for-authorship-attribution-modelling/versions/2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7012d3-a4e8-4343-b859-c5801d2eddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ceres/.cache/kagglehub/datasets/azimulh/tweets-data-for-authorship-attribution-modelling/versions/2/tweet.csv', '/home/ceres/.cache/kagglehub/datasets/azimulh/tweets-data-for-authorship-attribution-modelling/versions/2/tweet_with_authors.csv']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d40d36-cd67-4729-98f0-36ee88e00ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   author                                              tweet\n",
      "0     Neil deGrasse Tyson  A 50-yard field goal in MetLife stadium will d...\n",
      "1     Neil deGrasse Tyson  @PrintingJesus Yup. I occasionally repost afte...\n",
      "2     Neil deGrasse Tyson  @slstroud1 @TylerPhernetton False as stated. M...\n",
      "3     Neil deGrasse Tyson  The next time anybody asks me about my religio...\n",
      "4     Neil deGrasse Tyson  As climate change reshapes the World’s coastli...\n",
      "...                   ...                                                ...\n",
      "9903         Barack Obama  \"Progress isn’t guaranteed. It’s not inevitabl...\n",
      "9904         Barack Obama  America needs a budget that builds a stronger ...\n",
      "9905         Barack Obama  RT @WhiteHouse: FACT: Since @POTUS took office...\n",
      "9906         Barack Obama  LIVE: President Obama is speaking at the #WHCD...\n",
      "9907         Barack Obama  Of course, @MichelleObama’s my wife, so I’m a ...\n",
      "\n",
      "[9908 rows x 2 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fbb81f1-6eed-48a8-a69b-3ec6fb741704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Neil deGrasse Tyson\n",
      "1       Neil deGrasse Tyson\n",
      "2       Neil deGrasse Tyson\n",
      "3       Neil deGrasse Tyson\n",
      "4       Neil deGrasse Tyson\n",
      "               ...         \n",
      "9903           Barack Obama\n",
      "9904           Barack Obama\n",
      "9905           Barack Obama\n",
      "9906           Barack Obama\n",
      "9907           Barack Obama\n",
      "Name: author, Length: 9908, dtype: object\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a6ce5e8-035a-486c-b8df-9a59ebab523e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sebastian Ruder', 'Ellen DeGeneres', 'Barack Obama', 'Neil deGrasse Tyson', 'KATY PERRY'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02e57104-d4ff-45be-95a8-c61616345137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep: DON          | Vec: count_word_1-1\n",
      "{'acc': 0.8767650398258734, 'macro_f1': 0.8766916963023161}\n",
      "Prep: DON          | Vec: tfidf_word_1-1\n",
      "{'acc': 0.8706095393625924, 'macro_f1': 0.8688717054716129}\n",
      "Prep: DON          | Vec: count_char_3-5\n",
      "{'acc': 0.9173392944374179, 'macro_f1': 0.9171911709273759}\n",
      "Prep: DON          | Vec: tfidf_char_3-5\n",
      "{'acc': 0.9065400314083695, 'macro_f1': 0.9057020681441363}\n",
      "Prep: LOW          | Vec: count_word_1-1\n",
      "{'acc': 0.874242997680793, 'macro_f1': 0.8741392877735237}\n",
      "Prep: LOW          | Vec: tfidf_word_1-1\n",
      "{'acc': 0.870710345660159, 'macro_f1': 0.8688157437746675}\n",
      "Prep: LOW          | Vec: count_char_3-5\n",
      "{'acc': 0.9152198152886324, 'macro_f1': 0.9150822527896427}\n",
      "Prep: LOW          | Vec: tfidf_char_3-5\n",
      "{'acc': 0.9053289805116315, 'macro_f1': 0.9044079103264464}\n",
      "Prep: PUN          | Vec: count_word_1-1\n",
      "{'acc': 0.8767650398258734, 'macro_f1': 0.8766916963023161}\n",
      "Prep: PUN          | Vec: tfidf_word_1-1\n",
      "{'acc': 0.8706095393625924, 'macro_f1': 0.8688717054716129}\n",
      "Prep: PUN          | Vec: count_char_3-5\n",
      "{'acc': 0.8951351665239555, 'macro_f1': 0.8950284870832259}\n",
      "Prep: PUN          | Vec: tfidf_char_3-5\n",
      "{'acc': 0.8861517921770442, 'macro_f1': 0.8850444622104636}\n",
      "Prep: RSW          | Vec: count_word_1-1\n",
      "{'acc': 0.8653613465154081, 'macro_f1': 0.866007852960983}\n",
      "Prep: RSW          | Vec: tfidf_word_1-1\n",
      "{'acc': 0.8591037153666186, 'macro_f1': 0.8577233768404694}\n",
      "Prep: RSW          | Vec: count_char_3-5\n",
      "{'acc': 0.9210743231231513, 'macro_f1': 0.9210454434589884}\n",
      "Prep: RSW          | Vec: tfidf_char_3-5\n",
      "{'acc': 0.9068434181230265, 'macro_f1': 0.9066529411542973}\n",
      "Prep: LOW+URLrem+PUN | Vec: count_word_1-1\n",
      "{'acc': 0.8642513566062254, 'macro_f1': 0.864323882451093}\n",
      "Prep: LOW+URLrem+PUN | Vec: tfidf_word_1-1\n",
      "{'acc': 0.8626360108212683, 'macro_f1': 0.8614022968474474}\n",
      "Prep: LOW+URLrem+PUN | Vec: count_char_3-5\n",
      "{'acc': 0.8736378033294094, 'macro_f1': 0.8735794996438544}\n",
      "Prep: LOW+URLrem+PUN | Vec: tfidf_char_3-5\n",
      "{'acc': 0.8769679768089483, 'macro_f1': 0.8764500740363305}\n",
      "Prep: LOW+URLrem+PUN+RSW | Vec: count_word_1-1\n",
      "{'acc': 0.8515333101395651, 'macro_f1': 0.8526694030058903}\n",
      "Prep: LOW+URLrem+PUN+RSW | Vec: tfidf_word_1-1\n",
      "{'acc': 0.8557725740651222, 'macro_f1': 0.8546758257483134}\n",
      "Prep: LOW+URLrem+PUN+RSW | Vec: count_char_3-5\n",
      "{'acc': 0.8517365018126286, 'macro_f1': 0.8520099023195357}\n",
      "Prep: LOW+URLrem+PUN+RSW | Vec: tfidf_char_3-5\n",
      "{'acc': 0.8629390919079387, 'macro_f1': 0.862617473043372}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1e9f22-3d9d-49a6-97f7-eb00e384b240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         preprocessing      vectorizer       acc  macro_f1\n",
      "14                 RSW  count_char_3-5  0.921074  0.921045\n",
      "2                  DON  count_char_3-5  0.917339  0.917191\n",
      "6                  LOW  count_char_3-5  0.915220  0.915082\n",
      "15                 RSW  tfidf_char_3-5  0.906843  0.906653\n",
      "3                  DON  tfidf_char_3-5  0.906540  0.905702\n",
      "7                  LOW  tfidf_char_3-5  0.905329  0.904408\n",
      "10                 PUN  count_char_3-5  0.895135  0.895028\n",
      "11                 PUN  tfidf_char_3-5  0.886152  0.885044\n",
      "0                  DON  count_word_1-1  0.876765  0.876692\n",
      "8                  PUN  count_word_1-1  0.876765  0.876692\n",
      "19      LOW+URLrem+PUN  tfidf_char_3-5  0.876968  0.876450\n",
      "4                  LOW  count_word_1-1  0.874243  0.874139\n",
      "18      LOW+URLrem+PUN  count_char_3-5  0.873638  0.873579\n",
      "9                  PUN  tfidf_word_1-1  0.870610  0.868872\n",
      "1                  DON  tfidf_word_1-1  0.870610  0.868872\n",
      "5                  LOW  tfidf_word_1-1  0.870710  0.868816\n",
      "12                 RSW  count_word_1-1  0.865361  0.866008\n",
      "16      LOW+URLrem+PUN  count_word_1-1  0.864251  0.864324\n",
      "23  LOW+URLrem+PUN+RSW  tfidf_char_3-5  0.862939  0.862617\n",
      "17      LOW+URLrem+PUN  tfidf_word_1-1  0.862636  0.861402\n",
      "13                 RSW  tfidf_word_1-1  0.859104  0.857723\n",
      "21  LOW+URLrem+PUN+RSW  tfidf_word_1-1  0.855773  0.854676\n",
      "20  LOW+URLrem+PUN+RSW  count_word_1-1  0.851533  0.852669\n",
      "22  LOW+URLrem+PUN+RSW  count_char_3-5  0.851737  0.852010\n",
      "Saved to: Authorship_attribution_NoMAxFeat.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0994ae3-858d-4591-ad11-f19af39799df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
